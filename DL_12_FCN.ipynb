{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_12_FCN",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/031wnstjd/Deep-Learning/blob/master/DL_12_FCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_a1Rz3nVyJh"
      },
      "source": [
        "# DL_12 - FCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI4mr7ETdFSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "879cb9ca-4009-48cc-b09e-b9a78737427c"
      },
      "source": [
        "name = input(\"Name :\")\n",
        "ID = input(\"student ID :\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name :추준성\n",
            "student ID :2016145028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zg5Rku43lsq"
      },
      "source": [
        "## Semantic segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1t47gpQY7Ve"
      },
      "source": [
        "#### Prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx6pEYW3ZA6N"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86e_swtyaByD"
      },
      "source": [
        "####Dataset(VOC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2S8XOElaFfH"
      },
      "source": [
        "!wget -nc -O dataset/VOC2012_TrainVal.tar \"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\"\n",
        "\n",
        "!mkdir -p \"dataset\"\n",
        "!tar -xvf dataset/VOC2012_TrainVal.tar -C \"dataset\"\n",
        "!rm dataset/VOC2012_TrainVal.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "filTQaIoNZla"
      },
      "source": [
        "import os.path as osp\n",
        "\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image\n",
        "from torch.utils import data\n",
        "\n",
        "class VOC(data.Dataset):\n",
        "    \"\"\"\n",
        "    PASCAL VOC Segmentation dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root, split, ignore_label, mean_bgr, augment=True,\n",
        "        crop_size=224, scales=[1.0], flip=True):\n",
        "        super(VOC, self).__init__()\n",
        "\n",
        "        self.root = root\n",
        "        self.split = split\n",
        "        self.ignore_label = ignore_label\n",
        "        self.mean_bgr = np.array(mean_bgr)\n",
        "        self.augment = augment\n",
        "        self.crop_size = crop_size\n",
        "        self.scales = scales\n",
        "        self.flip = flip\n",
        "        self._set_files()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_id, image, label = self._load_data(index)\n",
        "        if self.augment:\n",
        "            image, label = self._augmentation(image, label)\n",
        "        # Mean subtraction\n",
        "        image -= self.mean_bgr\n",
        "        # HWC -> CHW\n",
        "        image = image.transpose(2, 0, 1)\n",
        "        return image_id, image.astype(np.float32), label.astype(np.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def _set_files(self):\n",
        "        self.root = osp.join(self.root, \"VOC2012\")\n",
        "        self.image_dir = osp.join(self.root, \"JPEGImages\")\n",
        "        self.label_dir = osp.join(self.root, \"SegmentationClass\")\n",
        "\n",
        "        if self.split in [\"train\", \"val\"]:\n",
        "            file_list = osp.join(\n",
        "                self.root, \"ImageSets/Segmentation\", self.split + \".txt\"\n",
        "            )\n",
        "            file_list = tuple(open(file_list, \"r\"))\n",
        "            file_list = [id_.rstrip() for id_ in file_list]\n",
        "            self.files = file_list\n",
        "        else:\n",
        "            raise ValueError(\"Invalid split name: {}\".format(self.split))\n",
        "\n",
        "    def _load_data(self, index):\n",
        "        # Set paths\n",
        "        image_id = self.files[index]\n",
        "        image_path = osp.join(self.image_dir, image_id + \".jpg\")\n",
        "        label_path = osp.join(self.label_dir, image_id + \".png\")\n",
        "        # Load an image\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_COLOR).astype(np.float32)\n",
        "        label = np.asarray(Image.open(label_path), dtype=np.int32)\n",
        "        return image_id, image, label\n",
        "\n",
        "    def _augmentation(self, image, label):\n",
        "        # Scaling\n",
        "        h, w = label.shape\n",
        "        scale_factor = random.choice(self.scales)\n",
        "        h, w = (int(h * scale_factor), int(w * scale_factor))\n",
        "        image = cv2.resize(image, (w, h), interpolation=cv2.INTER_LINEAR)\n",
        "        label = Image.fromarray(label).resize((w, h), resample=Image.NEAREST)\n",
        "        label = np.asarray(label, dtype=np.int64)\n",
        "        # Padding to fit for crop_size\n",
        "        h, w = label.shape\n",
        "        pad_h = max(self.crop_size - h, 0)\n",
        "        pad_w = max(self.crop_size - w, 0)\n",
        "        pad_kwargs = {\n",
        "            \"top\": 0,\n",
        "            \"bottom\": pad_h,\n",
        "            \"left\": 0,\n",
        "            \"right\": pad_w,\n",
        "            \"borderType\": cv2.BORDER_CONSTANT,\n",
        "        }\n",
        "        if pad_h > 0 or pad_w > 0:\n",
        "            image = cv2.copyMakeBorder(image, value=self.mean_bgr, **pad_kwargs)\n",
        "            label = cv2.copyMakeBorder(label, value=self.ignore_label, **pad_kwargs)\n",
        "        # Cropping\n",
        "        h, w = label.shape\n",
        "        start_h = random.randint(0, h - self.crop_size)\n",
        "        start_w = random.randint(0, w - self.crop_size)\n",
        "        end_h = start_h + self.crop_size\n",
        "        end_w = start_w + self.crop_size\n",
        "        image = image[start_h:end_h, start_w:end_w]\n",
        "        label = label[start_h:end_h, start_w:end_w]\n",
        "\n",
        "        if self.flip:\n",
        "            # Random flipping\n",
        "            if random.random() < 0.5:\n",
        "                image = np.fliplr(image).copy()  # HWC\n",
        "                label = np.fliplr(label).copy()  # HW\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUTgUNxwaJkV"
      },
      "source": [
        "batch_size = 8\n",
        "mean_bgr = [104.008, 116.669, 122.675]\n",
        "scales = [0.5, 0.75, 1.0, 1.25, 1.5]\n",
        "data_root = \"dataset/VOCdevkit\"\n",
        "\n",
        "trainset = VOC(root=data_root, split=\"train\", ignore_label=255,\n",
        "               mean_bgr=mean_bgr, augment=True, crop_size=224, scales=scales, flip=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = VOC(root=data_root, split=\"val\", ignore_label=255,\n",
        "              mean_bgr=mean_bgr, augment=False)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDfKXrceRswX"
      },
      "source": [
        "#### VGG16 FCN 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks_ZxKPZPj9H"
      },
      "source": [
        "class VGG16_FCN(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "        super(VGG16_FCN, self).__init__()\n",
        "\n",
        "        self.conv11 = nn.Conv2d(3, 64, 3, padding=1)\n",
        "        self.relu11 = nn.ReLU(True)\n",
        "        self.conv12 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.relu12 = nn.ReLU(True)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv21 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.relu21 = nn.ReLU(True)\n",
        "        self.conv22 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.relu22 = nn.ReLU(True)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv31 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.relu31 = nn.ReLU(True)\n",
        "        self.conv32 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.relu32 = nn.ReLU(True)\n",
        "        self.conv33 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.relu33 = nn.ReLU(True)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv41 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.relu41 = nn.ReLU(True)\n",
        "        self.conv42 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu42 = nn.ReLU(True)\n",
        "        self.conv43 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu43 = nn.ReLU(True)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv51 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu51 = nn.ReLU(True)\n",
        "        self.conv52 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu52 = nn.ReLU(True)\n",
        "        self.conv53 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu53 = nn.ReLU(True)\n",
        "        self.pool5 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc6 = nn.Conv2d(512, 4096, 1)\n",
        "        self.relu6 = nn.ReLU(True)\n",
        "        self.drop6 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
        "        self.relu7 = nn.ReLU(True)\n",
        "        self.drop7 = nn.Dropout(0.5)\n",
        "\n",
        "        self.score_fc = nn.Conv2d(4096, n_class, 1)\n",
        "\n",
        "        self.skip_pool3 = nn.Conv2d(256, n_class, 1)\n",
        "        self.skip_pool4 = nn.Conv2d(512, n_class, 1)\n",
        "\n",
        "        self.upscore2 = nn.ConvTranspose2d(n_class, n_class, 2, stride=2, bias=False)\n",
        "        self.upscore4 = nn.ConvTranspose2d(n_class, n_class, 2, stride=2, bias=False)\n",
        "        self.upscore8 = nn.ConvTranspose2d(n_class, n_class, 8, stride=8, bias=False)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # (batch_size, 3, 224, 224)\n",
        "        h = self.relu11(self.conv11(x))\n",
        "        h = self.relu12(self.conv12(h))\n",
        "        h = self.pool1(h)\n",
        "\n",
        "        # (batch_size, 64, 112, 112)\n",
        "        h = self.relu21(self.conv21(h))\n",
        "        h = self.relu22(self.conv22(h))\n",
        "        h = self.pool2(h)\n",
        "\n",
        "        # (batch_size, 128, 56, 56)\n",
        "        h = self.relu31(self.conv31(h))\n",
        "        h = self.relu32(self.conv32(h))\n",
        "        h = self.relu33(self.conv33(h))\n",
        "        h = self.pool3(h)\n",
        "        pool3 = h\n",
        "\n",
        "        # (batch_size, 256, 28, 28)\n",
        "        h = self.relu41(self.conv41(h))\n",
        "        h = self.relu42(self.conv42(h))\n",
        "        h = self.relu43(self.conv43(h))\n",
        "        h = self.pool4(h)\n",
        "        pool4 = h\n",
        "\n",
        "        # (batch_size, 512, 14, 14)\n",
        "        h = self.relu51(self.conv51(h))\n",
        "        h = self.relu52(self.conv52(h))\n",
        "        h = self.relu53(self.conv53(h))\n",
        "        h = self.pool5(h)\n",
        "\n",
        "        # (batch_size, 512, 7, 7)\n",
        "        h = self.relu6(self.fc6(h))\n",
        "        h = self.drop6(h)\n",
        "\n",
        "        # (batch_size, 4096, 7, 7)\n",
        "        h = self.relu7(self.fc7(h))\n",
        "        h = self.drop7(h)\n",
        "\n",
        "        # (batch_size, 4096, 7, 7)\n",
        "        h = self.score_fc(h)\n",
        "\n",
        "        # (batch_size, 21, 7, 7)\n",
        "        h = self.upscore2(h)\n",
        "        upscore2 = h # (batch_size, 21, 14, 14)\n",
        "\n",
        "        h = self.skip_pool4(pool4) # Skip connection for pool4: (batch_size, 21, 14, 14)\n",
        "        score_pool4c = h\n",
        "\n",
        "        h = upscore2 + score_pool4c # (batch_size, 21, 14, 14)\n",
        "        h = self.upscore4(h) # (batch_size, 21, 28, 28)\n",
        "        upscore_pool4 = h\n",
        "\n",
        "        h = self.skip_pool3(pool3) # Skip connection for pool3: (batch_size, 21, 28, 28)\n",
        "        score_pool3c = h\n",
        "\n",
        "        h = upscore_pool4 + score_pool3c # (batch_size, 21, 28, 28)\n",
        "\n",
        "        h = self.upscore8(h) # (batch_size, 21, 224, 224)\n",
        "\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW_7Dl5VZ8dq"
      },
      "source": [
        "####Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wN_YlZAZzRm"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "class trainer:\n",
        "  def __init__(self, model, train_loader, opt, epoch_size=10, learning_rate=1e-2, use_cuda=True ):\n",
        "    self.use_cuda = use_cuda #gpu 사용 여부\n",
        "    if use_cuda :\n",
        "      self.net = model.cuda() # gpu연산을 위한 model to gpu\n",
        "    else :\n",
        "      self.net = model\n",
        "    self.train_loader = train_loader \n",
        "    self.opt = opt # optmizer 종류 설정을 위한 인자\n",
        "    self.epoch_size = epoch_size # epoch\n",
        "    self.learning_rate = learning_rate \n",
        "    self.criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "\n",
        "  def train(self):\n",
        "  \n",
        "    #Optimizer\n",
        "    if self.opt == \"SGD\":\n",
        "      optimizer = optim.SGD(self.net.parameters(), lr=self.learning_rate) \n",
        "    elif self.opt == \"Adam\":\n",
        "      optimizer = optim.Adam(self.net.parameters(), lr=self.learning_rate)\n",
        "    print(len(self.train_loader))\n",
        "    for epoch in tqdm(range(self.epoch_size)):\n",
        "      self.net.train() # weight&bias를 update할 수 있는 상태로 변환\n",
        "      iter_loss = 0\n",
        "\n",
        "      for i, (image_id, inputs, targets) in enumerate(self.train_loader): \n",
        "        if self.use_cuda: #gpu연산\n",
        "          inputs = inputs.cuda() \n",
        "          targets = targets.cuda()\n",
        "\n",
        "        if i%30 == 0:\n",
        "            print(\"iter: \",i)\n",
        "\n",
        "        # gradient를 0으로 초기화\n",
        "        optimizer.zero_grad()\n",
        "        outputs = self.net(inputs) #forward\n",
        "        loss = self.criterion(outputs, targets) #loss계산\n",
        "        loss.backward() #backward -> gradient계산\n",
        "        optimizer.step() #최적화 -> weight&bias update\n",
        "        iter_loss += loss.item()\n",
        "\n",
        "        if i!=0 and i%30 == 0:\n",
        "            print(\"loss: \", iter_loss)\n",
        "            print(\"loss: \", loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3n7Z4l1cg7z"
      },
      "source": [
        "####Training & Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ev4eKWgalOu",
        "outputId": "6bc90dfe-b4fd-4b4d-db99-81f8aee2d10e"
      },
      "source": [
        "from torch.utils.model_zoo import load_url\n",
        "\n",
        "def remove_layer(state_dict, keyword):\n",
        "    keys = [key for key in state_dict.keys()]\n",
        "    for key in keys:\n",
        "        if keyword in key:\n",
        "            state_dict.pop(key)\n",
        "    return state_dict\n",
        "\n",
        "def replace_layer(state_dict, keyword1, keyword2):\n",
        "    keys = [key for key in state_dict.keys()]\n",
        "    for key in keys:\n",
        "        if keyword1 in key:\n",
        "            new_key = key.replace(keyword1, keyword2)\n",
        "            state_dict[new_key] = state_dict.pop(key)\n",
        "    return state_dict\n",
        "\n",
        "model_urls = {\n",
        "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth'\n",
        "}\n",
        "\n",
        "net = VGG16_FCN(n_class=21).cuda()\n",
        "state_dict = load_url(model_urls['vgg16'], progress=True)\n",
        "state_dict = remove_layer(state_dict, 'classifier.')\n",
        "\n",
        "key_list = list(state_dict.keys())\n",
        "for i,(name, p) in enumerate(net.named_parameters()):\n",
        "    if i==len(key_list):\n",
        "        break\n",
        "    state_dict = replace_layer(state_dict, key_list[i], name)\n",
        "net.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "trainer_FCN = trainer(net, trainloader, \"SGD\", epoch_size=3, learning_rate=1e-3)\n",
        "trainer_FCN.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter:  0\n",
            "iter:  30\n",
            "loss:  142.49564290046692\n",
            "loss:  tensor(3.5343, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  60\n",
            "loss:  211.08659529685974\n",
            "loss:  tensor(1.7048, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  90\n",
            "loss:  273.1525123119354\n",
            "loss:  tensor(2.0010, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  120\n",
            "loss:  335.3587040901184\n",
            "loss:  tensor(1.7154, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  150\n",
            "loss:  396.6994217634201\n",
            "loss:  tensor(1.6492, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  180\n",
            "loss:  456.0136696100235\n",
            "loss:  tensor(2.2027, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 1/3 [06:47<13:34, 407.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter:  0\n",
            "iter:  30\n",
            "loss:  59.72471272945404\n",
            "loss:  tensor(1.6166, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  60\n",
            "loss:  116.65999984741211\n",
            "loss:  tensor(1.6076, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  90\n",
            "loss:  171.96543431282043\n",
            "loss:  tensor(2.0568, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  120\n",
            "loss:  229.7346646785736\n",
            "loss:  tensor(1.5906, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  150\n",
            "loss:  282.92457258701324\n",
            "loss:  tensor(1.5006, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  180\n",
            "loss:  337.72025883197784\n",
            "loss:  tensor(2.0240, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [13:33<06:46, 406.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter:  0\n",
            "iter:  30\n",
            "loss:  58.1079021692276\n",
            "loss:  tensor(1.0321, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  60\n",
            "loss:  113.13843560218811\n",
            "loss:  tensor(2.4319, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  90\n",
            "loss:  168.06399524211884\n",
            "loss:  tensor(2.0649, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  120\n",
            "loss:  223.30292344093323\n",
            "loss:  tensor(2.2498, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  150\n",
            "loss:  275.9653570652008\n",
            "loss:  tensor(2.3770, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "iter:  180\n",
            "loss:  329.4944885969162\n",
            "loss:  tensor(1.4929, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [20:19<00:00, 406.55s/it]\n"
          ]
        }
      ]
    }
  ]
}